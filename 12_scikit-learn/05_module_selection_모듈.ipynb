{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_selection 모듈\n",
    "\n",
    "* 학습용 데이터와 테스트 데이터로 분리\n",
    "* 교차 검증 분할 및 평가\n",
    "* Estimator의 하이퍼 파라미터 튜닝을 위한 다양한 함수와 클래스 제공"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split() : 학습/테스트 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 점수 : 0.5340137746211778\n",
      "평가 데이터 점수 : 0.4554119451549796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "# train_test_split()은 4개를 return (vector 형태는 소문자, matrix 형태는 대문자)\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.3) # train data 70% / test data 30% 비율대로 데이터가 랜덤하게 섞인다\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train) # 학습을 위해 fit() method. 학습용 데이터인 X_train, y_train을 준다. \n",
    "\n",
    "print(\"학습 데이터 점수 : {}\".format(model.score(X_train, y_train))) # 학습데이터에 대한 점수 확인 (0 ~ 1)\n",
    "print(\"평가 데이터 점수 : {}\".format(model.score(X_test, y_test))) # 평가데이터에 대한 점수 확인 (0 ~ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "expected = y_test\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(predicted, expected)\n",
    "plt.plot([20, 350], [20, 350], '--r') \n",
    "plt.tight_layout()\n",
    "\n",
    "'''\n",
    "diabetes data가 넓게 분포되어있는 것을 알 수 있다.\n",
    "'--r'에 가까울수록 잘 맞는 것인데, 다음은 가깝지 않은 것들이 많다.\n",
    "따라서 다른 모델을 사용하거나 데이터 전처리를 통해서 개선해야 한다.\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val_score() : 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "# train_test_split()은 4개를 return (vector 형태는 소문자, matrix 형태는 대문자)\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.3) # train data 70% / test data 30% 비율대로 데이터가 랜덤하게 섞인다\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train) # 학습을 위해 fit() method. 학습용 데이터인 X_train, y_train을 준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 정확도 : [0.42955615 0.52259939 0.48268054 0.42649776 0.55024834]\n",
      "교차 검증 정확도 평균 : 0.48231643590864215 +/- 0.049268577511903826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = cross_val_score(model, diabetes.data, diabetes.target, cv=5) # cross validation을 위해 몇 개로 나눌지 (cv=5)\n",
    "\n",
    "print(\"교차 검증 정확도 : {}\".format(scores))\n",
    "print(\"교차 검증 정확도 평균 : {} +/- {}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchSV : 교차 검증과 최적 하이퍼 파라미터 찾기\n",
    "- 훈련 단계에서 학습한 파라미터에 영향을 받아서 최상의 파라미터를 찾는 일은 항상 어려운 문제\n",
    "- 다양한 모델의 훈련 과정을 자동화하고, 교차 검사를 사용해 최적값을 제공하는 도구 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 점수 : 0.46332219117960366\n",
      "최적 파라미터 : {'alpha': 0.1}\n",
      "Ridge(alpha=0.1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.554416</td>\n",
       "      <td>0.233683</td>\n",
       "      <td>0.356798</td>\n",
       "      <td>0.620262</td>\n",
       "      <td>0.267029</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.433004</td>\n",
       "      <td>0.433424</td>\n",
       "      <td>0.684991</td>\n",
       "      <td>0.462291</td>\n",
       "      <td>0.145852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.546298</td>\n",
       "      <td>0.244129</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.613735</td>\n",
       "      <td>0.271714</td>\n",
       "      <td>0.623092</td>\n",
       "      <td>0.426068</td>\n",
       "      <td>0.424745</td>\n",
       "      <td>0.429477</td>\n",
       "      <td>0.680918</td>\n",
       "      <td>0.462908</td>\n",
       "      <td>0.141449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.244984</td>\n",
       "      <td>0.383530</td>\n",
       "      <td>0.606595</td>\n",
       "      <td>0.286090</td>\n",
       "      <td>0.618034</td>\n",
       "      <td>0.431226</td>\n",
       "      <td>0.441777</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>0.662471</td>\n",
       "      <td>0.463322</td>\n",
       "      <td>0.132683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.421594</td>\n",
       "      <td>0.168441</td>\n",
       "      <td>0.358004</td>\n",
       "      <td>0.512609</td>\n",
       "      <td>0.284926</td>\n",
       "      <td>0.514263</td>\n",
       "      <td>0.388244</td>\n",
       "      <td>0.484445</td>\n",
       "      <td>0.396497</td>\n",
       "      <td>0.525135</td>\n",
       "      <td>0.405416</td>\n",
       "      <td>0.108386</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.159387</td>\n",
       "      <td>-0.081177</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>0.119348</td>\n",
       "      <td>0.186933</td>\n",
       "      <td>0.158146</td>\n",
       "      <td>0.203748</td>\n",
       "      <td>0.153626</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.077298</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>-0.234480</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>-0.012820</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.022647</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>-0.009908</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.026427</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'alpha': 1000}</td>\n",
       "      <td>-0.009602</td>\n",
       "      <td>-0.258118</td>\n",
       "      <td>-0.007849</td>\n",
       "      <td>-0.038479</td>\n",
       "      <td>-0.012933</td>\n",
       "      <td>-0.000932</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>-0.042679</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>-0.037073</td>\n",
       "      <td>0.075191</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.000428      0.000129         0.000144        0.000044       0.001   \n",
       "1       0.000294      0.000172         0.000107        0.000022        0.01   \n",
       "2       0.000209      0.000006         0.000091        0.000004         0.1   \n",
       "3       0.000198      0.000003         0.000088        0.000002           1   \n",
       "4       0.000208      0.000007         0.000091        0.000004          10   \n",
       "5       0.000202      0.000008         0.000090        0.000006         100   \n",
       "6       0.000197      0.000006         0.000085        0.000002        1000   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.001}           0.554416           0.233683           0.356798   \n",
       "1   {'alpha': 0.01}           0.546298           0.244129           0.368900   \n",
       "2    {'alpha': 0.1}           0.526551           0.244984           0.383530   \n",
       "3      {'alpha': 1}           0.421594           0.168441           0.358004   \n",
       "4     {'alpha': 10}           0.159387          -0.081177           0.152189   \n",
       "5    {'alpha': 100}           0.012468          -0.234480           0.013522   \n",
       "6   {'alpha': 1000}          -0.009602          -0.258118          -0.007849   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0           0.620262           0.267029           0.619402           0.419900   \n",
       "1           0.613735           0.271714           0.623092           0.426068   \n",
       "2           0.606595           0.286090           0.618034           0.431226   \n",
       "3           0.512609           0.284926           0.514263           0.388244   \n",
       "4           0.165690           0.119348           0.186933           0.158146   \n",
       "5          -0.012820           0.004838           0.022647           0.022028   \n",
       "6          -0.038479          -0.012933          -0.000932           0.001768   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0           0.433004           0.433424           0.684991         0.462291   \n",
       "1           0.424745           0.429477           0.680918         0.462908   \n",
       "2           0.441777           0.431962           0.662471         0.463322   \n",
       "3           0.484445           0.396497           0.525135         0.405416   \n",
       "4           0.203748           0.153626           0.189441         0.140733   \n",
       "5          -0.009908           0.015589           0.026427        -0.013969   \n",
       "6          -0.042679          -0.004652           0.002744        -0.037073   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.145852                3  \n",
       "1        0.141449                2  \n",
       "2        0.132683                1  \n",
       "3        0.108386                4  \n",
       "4        0.077298                5  \n",
       "5        0.074561                6  \n",
       "6        0.075191                7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
    "param_grid = dict(alpha=alpha) # parameter값을 모두 다르게 하여 모델을 계속 cross_validation(교차검증) 진행\n",
    "\n",
    "gs = GridSearchCV(estimator=Ridge(), param_grid=param_grid, cv=10) \n",
    "result = gs.fit(diabetes.data, diabetes.target)\n",
    "\n",
    "print(\"최적 점수 : {}\".format(result.best_score_))\n",
    "print(\"최적 파라미터 : {}\".format(result.best_params_))\n",
    "print(gs.best_estimator_)\n",
    "pd.DataFrame(result.cv_results_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiprocessing을 이용한 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 점수 : 0.9800000000000001\n",
      "최적 파라미터 : {'C': 2.4, 'penalty': 'l2'}\n",
      "LogisticRegression(C=2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.96666667        nan 0.97333333        nan 0.97333333\n",
      "        nan 0.97333333        nan 0.97333333        nan 0.98      ]\n",
      "  warnings.warn(\n",
      "/Users/ihyeongseob/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.5, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>1.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.5, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.8, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>1.8</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.8, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 2.0, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 2.0, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 2.4, 'penalty': 'l1'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.4</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 2.4, 'penalty': 'l2'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.000791      0.001796         0.000000        0.000000     0.5   \n",
       "1        0.006412      0.003133         0.000277        0.000075     0.5   \n",
       "2        0.000148      0.000028         0.000000        0.000000     1.0   \n",
       "3        0.013255      0.005972         0.000304        0.000118     1.0   \n",
       "4        0.000178      0.000112         0.000000        0.000000     1.5   \n",
       "5        0.009444      0.005584         0.000407        0.000473     1.5   \n",
       "6        0.000127      0.000013         0.000000        0.000000     1.8   \n",
       "7        0.007424      0.004566         0.000352        0.000416     1.8   \n",
       "8        0.000129      0.000021         0.000000        0.000000     2.0   \n",
       "9        0.008656      0.005547         0.000260        0.000111     2.0   \n",
       "10       0.000422      0.000681         0.000000        0.000000     2.4   \n",
       "11       0.007922      0.003858         0.000227        0.000029     2.4   \n",
       "\n",
       "   param_penalty                       params  split0_test_score  \\\n",
       "0             l1  {'C': 0.5, 'penalty': 'l1'}                NaN   \n",
       "1             l2  {'C': 0.5, 'penalty': 'l2'}                1.0   \n",
       "2             l1  {'C': 1.0, 'penalty': 'l1'}                NaN   \n",
       "3             l2  {'C': 1.0, 'penalty': 'l2'}                1.0   \n",
       "4             l1  {'C': 1.5, 'penalty': 'l1'}                NaN   \n",
       "5             l2  {'C': 1.5, 'penalty': 'l2'}                1.0   \n",
       "6             l1  {'C': 1.8, 'penalty': 'l1'}                NaN   \n",
       "7             l2  {'C': 1.8, 'penalty': 'l2'}                1.0   \n",
       "8             l1  {'C': 2.0, 'penalty': 'l1'}                NaN   \n",
       "9             l2  {'C': 2.0, 'penalty': 'l2'}                1.0   \n",
       "10            l1  {'C': 2.4, 'penalty': 'l1'}                NaN   \n",
       "11            l2  {'C': 2.4, 'penalty': 'l2'}                1.0   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.933333                1.0           0.933333   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.933333                1.0           1.000000   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.933333                1.0           1.000000   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.933333                1.0           1.000000   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.933333                1.0           1.000000   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.933333                1.0           1.000000   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.933333           0.933333           0.933333   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.933333           0.933333           0.933333   \n",
       "4                 NaN                NaN                NaN   \n",
       "5            0.933333           0.933333           0.933333   \n",
       "6                 NaN                NaN                NaN   \n",
       "7            0.933333           0.933333           0.933333   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.933333           0.933333           0.933333   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.933333           1.000000           0.933333   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0                 NaN                NaN                NaN              NaN   \n",
       "1                 1.0                1.0                1.0         0.966667   \n",
       "2                 NaN                NaN                NaN              NaN   \n",
       "3                 1.0                1.0                1.0         0.973333   \n",
       "4                 NaN                NaN                NaN              NaN   \n",
       "5                 1.0                1.0                1.0         0.973333   \n",
       "6                 NaN                NaN                NaN              NaN   \n",
       "7                 1.0                1.0                1.0         0.973333   \n",
       "8                 NaN                NaN                NaN              NaN   \n",
       "9                 1.0                1.0                1.0         0.973333   \n",
       "10                NaN                NaN                NaN              NaN   \n",
       "11                1.0                1.0                1.0         0.980000   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0              NaN                7  \n",
       "1         0.033333                6  \n",
       "2              NaN                7  \n",
       "3         0.032660                2  \n",
       "4              NaN                7  \n",
       "5         0.032660                2  \n",
       "6              NaN                7  \n",
       "7         0.032660                2  \n",
       "8              NaN                7  \n",
       "9         0.032660                2  \n",
       "10             NaN                7  \n",
       "11        0.030551                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "param_grid = [{\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : [0.5, 1.0, 1.5, 1.8, 2.0, 2.4]\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=LogisticRegression(), \n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy', cv=10, n_jobs=multiprocessing.cpu_count()\n",
    ") # cpu개수만큼 job생성하여 수행\n",
    "result = gs.fit(iris.data, iris.target)\n",
    "\n",
    "print(\"최적 점수 : {}\".format(result.best_score_))\n",
    "print(\"최적 파라미터 : {}\".format(result.best_params_))\n",
    "print(gs.best_estimator_)\n",
    "pd.DataFrame(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fa5e1eba17a09ed460996a78ce2364a88c028d5d0b053615ee12cbef51e120d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
